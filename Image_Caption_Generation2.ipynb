{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Caption_Generation2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "weESE7HHIZTA"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_dA_8Sy00_t",
        "outputId": "023d895a-1dc7-438c-dc65-3fd28a6082d4"
      },
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-27 04:18:56--  https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/124585957/47f52b80-3501-11e9-8f49-4515a2a3339b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210527%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210527T041857Z&X-Amz-Expires=300&X-Amz-Signature=c0c374c3570a394f94486d6326a2491eb66ac2573096945486927534764b0964&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=124585957&response-content-disposition=attachment%3B%20filename%3DFlickr8k_Dataset.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-05-27 04:18:57--  https://github-releases.githubusercontent.com/124585957/47f52b80-3501-11e9-8f49-4515a2a3339b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210527%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210527T041857Z&X-Amz-Expires=300&X-Amz-Signature=c0c374c3570a394f94486d6326a2491eb66ac2573096945486927534764b0964&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=124585957&response-content-disposition=attachment%3B%20filename%3DFlickr8k_Dataset.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115419746 (1.0G) [application/octet-stream]\n",
            "Saving to: ‘Flickr8k_Dataset.zip’\n",
            "\n",
            "Flickr8k_Dataset.zi 100%[===================>]   1.04G  91.9MB/s    in 11s     \n",
            "\n",
            "2021-05-27 04:19:08 (93.9 MB/s) - ‘Flickr8k_Dataset.zip’ saved [1115419746/1115419746]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWKeocPj9WnU"
      },
      "source": [
        "!unzip /content/Flickr8k_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36ko3XX2-w6Z"
      },
      "source": [
        "!wget https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hCtNaEM-47y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "471fd26b-d4a6-4f41-ddd2-cc78ea61e841"
      },
      "source": [
        "!unzip /content/Flickr8k_text.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/Flickr8k_text.zip\n",
            "  inflating: CrowdFlowerAnnotations.txt  \n",
            "  inflating: ExpertAnnotations.txt   \n",
            "  inflating: Flickr8k.lemma.token.txt  \n",
            "  inflating: __MACOSX/._Flickr8k.lemma.token.txt  \n",
            "  inflating: Flickr8k.token.txt      \n",
            "  inflating: Flickr_8k.devImages.txt  \n",
            "  inflating: Flickr_8k.testImages.txt  \n",
            "  inflating: Flickr_8k.trainImages.txt  \n",
            "  inflating: readme.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf-dy2VHIQ_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbb7681-4c5a-4e09-da1d-b830e37a3eb1"
      },
      "source": [
        "token_path = '/content/Flickr8k.token.txt'\n",
        "text = open(token_path, 'r')\n",
        "text = text.read()\n",
        "print(text[:410])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000268201_693b08cb0e.jpg#0\tA child in a pink dress is climbing up a set of stairs in an entry way .\n",
            "1000268201_693b08cb0e.jpg#1\tA girl going into a wooden building .\n",
            "1000268201_693b08cb0e.jpg#2\tA little girl climbing into a wooden playhouse .\n",
            "1000268201_693b08cb0e.jpg#3\tA little girl climbing the stairs to her playhouse .\n",
            "1000268201_693b08cb0e.jpg#4\tA little girl in a pink dress going into a wooden cabin .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UpZxbPQ8cNp"
      },
      "source": [
        "def load_description(text):\n",
        "    mapping = dict()\n",
        "    for line in text.split(\"\\n\"):\n",
        "        token = line.split(\"\\t\")\n",
        "        if len(line) < 2:\n",
        "            continue\n",
        "        img_id = token[0].split('.')[0]\n",
        "        img_des = token[1]\n",
        "        if img_id not in mapping:\n",
        "            mapping[img_id] = list()\n",
        "        mapping[img_id].append(img_des)\n",
        "    return mapping"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rboasTaUIaDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e054286-92cf-48e2-d987-6df7b4680090"
      },
      "source": [
        "descriptions = load_description(text)\n",
        "print(\"Number of items: \" + str(len(descriptions)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of items: 8092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtT1vZMC8ugx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f705ecbf-8745-41f0-eb14-4e3dcc3204ba"
      },
      "source": [
        "descriptions['1000268201_693b08cb0e']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
              " 'A girl going into a wooden building .',\n",
              " 'A little girl climbing into a wooden playhouse .',\n",
              " 'A little girl climbing the stairs to her playhouse .',\n",
              " 'A little girl in a pink dress going into a wooden cabin .']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJsx5Wqm-kO3"
      },
      "source": [
        "import string\n",
        "def clean_description(desc):\n",
        "    for key, des_list in desc.items():\n",
        "        for i in range(len(des_list)):\n",
        "            caption = des_list[i]\n",
        "            caption = [ch for ch in caption if ch not in string.punctuation]\n",
        "            caption = ''.join(caption)\n",
        "            caption = caption.split(' ')\n",
        "            caption = [word.lower() for word in caption if len(word)>1 and word.isalpha()]\n",
        "            caption = ' '.join(caption)\n",
        "            des_list[i] = caption"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb2KKm_io1_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369c2384-7070-4f2b-f37c-0a17a24bc218"
      },
      "source": [
        "clean_description(descriptions)\n",
        "descriptions['1000268201_693b08cb0e']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['child in pink dress is climbing up set of stairs in an entry way',\n",
              " 'girl going into wooden building',\n",
              " 'little girl climbing into wooden playhouse',\n",
              " 'little girl climbing the stairs to her playhouse',\n",
              " 'little girl in pink dress going into wooden cabin']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5SCcb5TIkgR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec00f967-5c38-4b74-f7cc-b1c94cbd79f5"
      },
      "source": [
        "import glob\n",
        "images = '/content/Flicker8k_Dataset/'\n",
        "img = glob.glob(images + '*.jpg')\n",
        "len(img)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8091"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8xLUGrEKViR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c2b1a6-afbb-4d07-bfc6-dfe842084385"
      },
      "source": [
        "train_path = '/content/Flickr_8k.trainImages.txt'\n",
        "train_images = open(train_path, 'r').read().split(\"\\n\")\n",
        "train_img = []\n",
        "\n",
        "for im in img:\n",
        "    if(im[len(images):] in train_images):\n",
        "        train_img.append(im)\n",
        "len(train_img)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCESPtsMsEiD"
      },
      "source": [
        "def load_clean_descriptions(des, dataset):\n",
        "    dataset_des = dict()\n",
        "    for key, des_list in des.items():\n",
        "        if key+'.jpg' in dataset:\n",
        "            dataset_des[key] = list()\n",
        "            for line in des_list:\n",
        "                desc = 'start ' + line + ' end'\n",
        "                dataset_des[key].append(desc)\n",
        "    return dataset_des\n",
        "  \n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cWKAIA4sGSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d106ca6-1c07-4773-c3c3-6e52adc58763"
      },
      "source": [
        "train_descriptions = load_clean_descriptions(descriptions, train_images)\n",
        "print(train_descriptions['1000268201_693b08cb0e'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['start child in pink dress is climbing up set of stairs in an entry way end', 'start girl going into wooden building end', 'start little girl climbing into wooden playhouse end', 'start little girl climbing the stairs to her playhouse end', 'start little girl in pink dress going into wooden cabin end']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JymIeSAoKcXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf5aa48-d92e-44d5-9e9f-76efc0dfb155"
      },
      "source": [
        "test_path = '/content/Flickr_8k.testImages.txt'\n",
        "test_images = open(test_path, 'r').read().split(\"\\n\")\n",
        "test_img = []\n",
        "\n",
        "for im in img:\n",
        "    if(im[len(images): ] in test_images):\n",
        "        test_img.append(im)\n",
        "len(test_img)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zEDL1gtCnj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df32a096-90f6-4c99-d54d-7ff6270425df"
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.models import Model\n",
        "\n",
        "def preprocess_img(img_path):\n",
        "\timg = load_img(img_path, target_size = (299, 299))\n",
        "\tx = img_to_array(img)\n",
        "\tx = np.expand_dims(x, axis = 0)\n",
        "\tx = preprocess_input(x)\n",
        "\treturn x\n",
        "\n",
        "def encode(image):\n",
        "\timage = preprocess_img(image)\n",
        "\tvec = model.predict(image)\n",
        "\tvec = np.reshape(vec, (vec.shape[1]))\n",
        "\treturn vec\n",
        "\n",
        "base_model = InceptionV3(weights = 'imagenet')\n",
        "model = Model(base_model.input, base_model.layers[-2].output)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "96124928/96112376 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMctsrnZCbkM"
      },
      "source": [
        "encoding_train = {}\n",
        "for img in train_img:\n",
        "\tencoding_train[img[len(images):]] = encode(img)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsac_1m-I5s1"
      },
      "source": [
        "encoding_test = {}\n",
        "for img in test_img:\n",
        "    encoding_test[img[len(images):]] = encode(img)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LdRxDeVNzVq"
      },
      "source": [
        "train_features = encoding_train\n",
        "test_features = encoding_test"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ73Zb_xJytv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc6cb48-8899-45d1-f039-473218ebd98a"
      },
      "source": [
        "all_train_captions = []\n",
        "for key, val in train_descriptions.items():\n",
        "    for caption in val:\n",
        "        all_train_captions.append(caption)\n",
        "len(all_train_captions)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIrGTwzEKBE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3667674-f397-4656-f419-5f3b1cd3d0c6"
      },
      "source": [
        "threshold = 5\n",
        "word_counts = {}\n",
        "for cap in all_train_captions:\n",
        "    for word in cap.split(' '):\n",
        "        word_counts[word] = word_counts.get(word, 0) + 1\n",
        "\n",
        "vocab = [word for word in word_counts if word_counts[word] >= threshold]\n",
        "print(\"Unique words: \" + str(len(word_counts)))\n",
        "print(\"our Vocabulary: \" + str(len(vocab)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words: 7576\n",
            "our Vocabulary: 2528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64ukVx3ALSp5"
      },
      "source": [
        "ixtoword = {}\n",
        "wordtoix = {}\n",
        "\n",
        "ix = 1\n",
        "for word in vocab:\n",
        "    wordtoix[word] = ix\n",
        "    ixtoword[ix] = word\n",
        "    ix += 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4OSgOx8MWJO"
      },
      "source": [
        "vocab_size = len(ixtoword) + 1\n",
        "max_length = max(len(des.split()) for des in all_train_captions)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "innf2w-uNlVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc64e2b-a5e4-4211-f81c-0264d04250fd"
      },
      "source": [
        "import keras\n",
        "import keras.utils\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "X1, X2, y = list(), list(), list()\n",
        "for key, des_list in train_descriptions.items():\n",
        "    pic = train_features[key + '.jpg']\n",
        "    for cap in des_list:\n",
        "        seq = [wordtoix[word] for word in cap.split(' ') if word in wordtoix]\n",
        "        for i in range(1, len(seq)):\n",
        "            in_seq, out_seq = seq[:i], seq[i]\n",
        "            in_seq = pad_sequences([in_seq], maxlen = max_length)[0]\n",
        "            out_seq = to_categorical([out_seq], num_classes = vocab_size)[0]\n",
        "            #store\n",
        "            X1.append(pic)\n",
        "            X2.append(in_seq)\n",
        "            y.append(out_seq)\n",
        "\n",
        "X2 = np.array(X2)\n",
        "X1 = np.array(X1)\n",
        "y = np.array(y)\n",
        "print(X1.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(298088, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJgFJY3zcfnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7b0f44e-b584-4f6e-de7a-b289a4254d82"
      },
      "source": [
        "embeddings_index = {}\n",
        "glove = open('/content/glove.6B.200d.txt', 'r', encoding = 'utf-8').read()\n",
        "for line in glove.split(\"\\n\"):\n",
        "    values = line.split(\" \")\n",
        "    word = values[0]\n",
        "    indices = np.asarray(values[1: ], dtype = 'float32')\n",
        "    embeddings_index[word] = indices\n",
        "print('Total word vectors: ' + str(len(embeddings_index)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total word vectors: 32898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dOF-EoHeoKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba41ab3a-513c-44e7-8b20-f449577d21b8"
      },
      "source": [
        "emb_dim = 200\n",
        "emb_matrix = np.zeros((vocab_size, emb_dim))\n",
        "for word, i in wordtoix.items():\n",
        "    emb_vec = embeddings_index.get(word)\n",
        "    if emb_vec is not None:\n",
        "        emb_matrix[i] = emb_vec\n",
        "emb_matrix.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2529, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHxPBHhpii1R"
      },
      "source": [
        "**Defining the Model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qw4tTi3iMsL"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Embedding, LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by6SVJ3tGSDg"
      },
      "source": [
        "caption_generator = Sequential()\n",
        "caption_generator.add(InputLayer(input_shape=(None,max_length)))"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UA9XdHJZGSTx"
      },
      "source": [
        "caption_generator.add(Embedding(vocab_size, 200,input_length=max_length, mask_zero=True))"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_811F_9GSgJ"
      },
      "source": [
        "caption_generator.add(Dropout(0.2))\n",
        "INPUT_SHAPE = [ None, 34, 200]\n",
        "caption_generator.add(LSTM(units = 256, input_shape=INPUT_SHAPE))"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_c17DjuLhvE"
      },
      "source": [
        "caption_generator.build(input_shape=(None,max_length))"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgmnrppxudyH"
      },
      "source": [
        "classifier = Sequential()"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL0c3n5TAySP"
      },
      "source": [
        "classifier.add(InputLayer(input_shape=(None,2048)))"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk3mt94ixfOq"
      },
      "source": [
        "classifier.add(Dropout(0.5))"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmpeO34QxlXa"
      },
      "source": [
        "classifier.add(Dense(units = 256, activation = 'softmax'))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz3Ss7azd8fP"
      },
      "source": [
        "classifier.build(input_shape=(None,2048))"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L7KJJDO9Mm1"
      },
      "source": [
        "from keras.layers import Concatenate\n",
        "conca = Concatenate()([classifier.output, caption_generator.output])"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndkb1NwfNHtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ede2c2-314f-4b45-f9b7-c1b4c8ca4e8f"
      },
      "source": [
        "x = Dense(vocab_size, activation='softmax')(conca)\n",
        "model1 = Model(inputs=[classifier.input, caption_generator.input], outputs = x)\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model1.summary()"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "module_wrapper_1_input (InputLa [(None, 34)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "module_wrapper_5_input (InputLa [(None, 2048)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "module_wrapper_1 (ModuleWrapper (None, 34)           0           module_wrapper_1_input[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "module_wrapper_5 (ModuleWrapper (None, 2048)         0           module_wrapper_5_input[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "module_wrapper_2 (ModuleWrapper (None, 34, 200)      505800      module_wrapper_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 2048)         0           module_wrapper_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 34, 200)      0           module_wrapper_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          524544      dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "module_wrapper_3 (ModuleWrapper (None, 256)          467968      dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 512)          0           dense_1[0][0]                    \n",
            "                                                                 module_wrapper_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2529)         1297377     concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,795,689\n",
            "Trainable params: 2,795,689\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}